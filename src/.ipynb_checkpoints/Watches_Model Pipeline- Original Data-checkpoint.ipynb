{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build model for watch price utilizing linear regression and lightgbm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from lightgbm import LGBMRegressor\n",
    "import lightgbm as lgb\n",
    "import pickle as pkl\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "import statsmodels.api as sm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.linear_model import Lasso, Ridge, LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'data/reformatedAndOneHotEncodedDataVer011.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(file, index_col=[0])\n",
    "## Re-ordering to ascending order\n",
    "df = df.iloc[::-1]\n",
    "df.drop(columns = 'Unnamed: 0', inplace=True)\n",
    "df['listing__statPrice'] = df['listing__statPrice'].round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['listing__statPrice', 'allDiamond', 'preciousStone', 'someDiamonds',\n",
       "       'braceletRubber', 'braceletLeather', 'braceletFabric', 'braceletMetal',\n",
       "       'caseGold', 'caseEverose', 'caseRose', 'caseStainless', 'caseOyster',\n",
       "       'caseYellow', 'caseDiamond', 'caseSteel', 'caseWhite', 'casePlatinum',\n",
       "       'CaseSize32', 'CaseSize34', 'CaseSize36', 'CaseSize38', 'CaseSize40',\n",
       "       'CaseSize42', 'CaseSize44', 'Movementautomatic', 'Movementquartz',\n",
       "       'Movementmanual', 'PapersYes', 'PapersNo', 'BoxYes', 'BoxNo',\n",
       "       'ConditionAA', 'ConditionAAA', 'ConditionA', 'ConditionB',\n",
       "       'Conditionother', 'Manufacture2018-2022', 'Manufacture2013-2017',\n",
       "       'Manufacture2008-2012', 'Manufacture2003-2007', 'ManufactureVintage',\n",
       "       'Productdaydate', 'Productdatejust', 'Productoysterperpetual',\n",
       "       'Productladydatejust', 'Productcellini', 'Productairking',\n",
       "       'Productgmtmaster', 'Productyachtmaster', 'Productsubmariner',\n",
       "       'Productcosmographdaytona', 'Productseadweller', 'Productskydweller',\n",
       "       'Productexplorer', 'Productmilgauss', 'Productother'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>listing__statPrice</th>\n",
       "      <th>allDiamond</th>\n",
       "      <th>preciousStone</th>\n",
       "      <th>someDiamonds</th>\n",
       "      <th>braceletRubber</th>\n",
       "      <th>braceletLeather</th>\n",
       "      <th>braceletFabric</th>\n",
       "      <th>braceletMetal</th>\n",
       "      <th>caseGold</th>\n",
       "      <th>caseEverose</th>\n",
       "      <th>caseRose</th>\n",
       "      <th>caseStainless</th>\n",
       "      <th>caseOyster</th>\n",
       "      <th>caseYellow</th>\n",
       "      <th>caseDiamond</th>\n",
       "      <th>caseSteel</th>\n",
       "      <th>caseWhite</th>\n",
       "      <th>casePlatinum</th>\n",
       "      <th>CaseSize32</th>\n",
       "      <th>CaseSize34</th>\n",
       "      <th>CaseSize36</th>\n",
       "      <th>CaseSize38</th>\n",
       "      <th>CaseSize40</th>\n",
       "      <th>CaseSize42</th>\n",
       "      <th>CaseSize44</th>\n",
       "      <th>Movementautomatic</th>\n",
       "      <th>Movementquartz</th>\n",
       "      <th>Movementmanual</th>\n",
       "      <th>PapersYes</th>\n",
       "      <th>PapersNo</th>\n",
       "      <th>BoxYes</th>\n",
       "      <th>BoxNo</th>\n",
       "      <th>ConditionAA</th>\n",
       "      <th>ConditionAAA</th>\n",
       "      <th>ConditionA</th>\n",
       "      <th>ConditionB</th>\n",
       "      <th>Conditionother</th>\n",
       "      <th>Manufacture2018-2022</th>\n",
       "      <th>Manufacture2013-2017</th>\n",
       "      <th>Manufacture2008-2012</th>\n",
       "      <th>Manufacture2003-2007</th>\n",
       "      <th>ManufactureVintage</th>\n",
       "      <th>Productdaydate</th>\n",
       "      <th>Productdatejust</th>\n",
       "      <th>Productoysterperpetual</th>\n",
       "      <th>Productladydatejust</th>\n",
       "      <th>Productcellini</th>\n",
       "      <th>Productairking</th>\n",
       "      <th>Productgmtmaster</th>\n",
       "      <th>Productyachtmaster</th>\n",
       "      <th>Productsubmariner</th>\n",
       "      <th>Productcosmographdaytona</th>\n",
       "      <th>Productseadweller</th>\n",
       "      <th>Productskydweller</th>\n",
       "      <th>Productexplorer</th>\n",
       "      <th>Productmilgauss</th>\n",
       "      <th>Productother</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>845</th>\n",
       "      <td>39996.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>844</th>\n",
       "      <td>20687.62</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>843</th>\n",
       "      <td>19446.37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>842</th>\n",
       "      <td>24134.25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>841</th>\n",
       "      <td>16204.42</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     listing__statPrice  allDiamond  preciousStone  someDiamonds  \\\n",
       "845            39996.07           0              0             0   \n",
       "844            20687.62           0              0             0   \n",
       "843            19446.37           0              0             0   \n",
       "842            24134.25           0              0             0   \n",
       "841            16204.42           0              0             0   \n",
       "\n",
       "     braceletRubber  braceletLeather  braceletFabric  braceletMetal  caseGold  \\\n",
       "845               0                0               0              1         1   \n",
       "844               0                0               0              1         0   \n",
       "843               0                0               0              1         0   \n",
       "842               0                0               0              1         0   \n",
       "841               0                0               0              1         0   \n",
       "\n",
       "     caseEverose  caseRose  caseStainless  caseOyster  caseYellow  \\\n",
       "845            0         0              0           0           0   \n",
       "844            0         0              1           0           0   \n",
       "843            0         0              1           0           0   \n",
       "842            0         0              1           0           0   \n",
       "841            0         0              1           0           0   \n",
       "\n",
       "     caseDiamond  caseSteel  caseWhite  casePlatinum  CaseSize32  CaseSize34  \\\n",
       "845            0          0          1             0           0           0   \n",
       "844            0          1          0             0           0           0   \n",
       "843            0          1          0             0           0           0   \n",
       "842            0          1          0             0           0           0   \n",
       "841            0          1          0             0           0           0   \n",
       "\n",
       "     CaseSize36  CaseSize38  CaseSize40  CaseSize42  CaseSize44  \\\n",
       "845           0           0           1           0           0   \n",
       "844           0           0           1           0           0   \n",
       "843           0           0           1           0           0   \n",
       "842           0           0           1           0           0   \n",
       "841           0           0           0           0           1   \n",
       "\n",
       "     Movementautomatic  Movementquartz  Movementmanual  PapersYes  PapersNo  \\\n",
       "845                  1               0               0          1         0   \n",
       "844                  1               0               0          1         0   \n",
       "843                  1               0               0          1         0   \n",
       "842                  1               0               0          0         1   \n",
       "841                  1               0               0          1         0   \n",
       "\n",
       "     BoxYes  BoxNo  ConditionAA  ConditionAAA  ConditionA  ConditionB  \\\n",
       "845       1      0            0             0           0           0   \n",
       "844       1      0            0             0           0           0   \n",
       "843       1      0            0             0           0           0   \n",
       "842       0      1            0             0           0           0   \n",
       "841       1      0            0             0           0           0   \n",
       "\n",
       "     Conditionother  Manufacture2018-2022  Manufacture2013-2017  \\\n",
       "845               1                     1                     0   \n",
       "844               1                     1                     0   \n",
       "843               1                     1                     0   \n",
       "842               1                     0                     0   \n",
       "841               1                     0                     1   \n",
       "\n",
       "     Manufacture2008-2012  Manufacture2003-2007  ManufactureVintage  \\\n",
       "845                     0                     0                   0   \n",
       "844                     0                     0                   0   \n",
       "843                     0                     0                   0   \n",
       "842                     0                     0                   1   \n",
       "841                     0                     0                   0   \n",
       "\n",
       "     Productdaydate  Productdatejust  Productoysterperpetual  \\\n",
       "845               0                0                       0   \n",
       "844               0                0                       0   \n",
       "843               0                0                       0   \n",
       "842               1                0                       0   \n",
       "841               0                0                       0   \n",
       "\n",
       "     Productladydatejust  Productcellini  Productairking  Productgmtmaster  \\\n",
       "845                    0               0               0                 1   \n",
       "844                    0               0               0                 0   \n",
       "843                    0               0               0                 1   \n",
       "842                    0               0               0                 0   \n",
       "841                    0               0               0                 0   \n",
       "\n",
       "     Productyachtmaster  Productsubmariner  Productcosmographdaytona  \\\n",
       "845                   0                  0                         0   \n",
       "844                   0                  1                         0   \n",
       "843                   0                  0                         0   \n",
       "842                   0                  0                         1   \n",
       "841                   0                  0                         0   \n",
       "\n",
       "     Productseadweller  Productskydweller  Productexplorer  Productmilgauss  \\\n",
       "845                  0                  0                0                0   \n",
       "844                  0                  0                0                0   \n",
       "843                  0                  0                0                0   \n",
       "842                  0                  0                0                0   \n",
       "841                  1                  0                0                0   \n",
       "\n",
       "     Productother  \n",
       "845             0  \n",
       "844             0  \n",
       "843             0  \n",
       "842             0  \n",
       "841             0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['listing__statPrice']\n",
    "X = df.drop(columns=['listing__statPrice'], axis=1)\n",
    "\n",
    "# Shuffle to false to handle time data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle=False, test_size = 0.2)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, shuffle=False, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create full train data for final model\n",
    "Xtrain = pd.concat([X_train,X_val])\n",
    "ytrain = np.concatenate((y_train, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_pipe = make_pipeline(\n",
    "    StandardScaler(with_mean=True), \n",
    "    LinearRegression()\n",
    ")\n",
    "\n",
    "lasso_pipe = make_pipeline(\n",
    "    StandardScaler(with_mean=True), \n",
    "    Lasso()\n",
    ")\n",
    "\n",
    "ridge_pipe = make_pipeline(\n",
    "    StandardScaler(with_mean=True), \n",
    "    Ridge()\n",
    ")\n",
    "\n",
    "rf_pipe = make_pipeline(\n",
    "    StandardScaler(with_mean=True), \n",
    "    RandomForestRegressor(random_state = 42)\n",
    ")\n",
    "\n",
    "lgbm_pipe = make_pipeline(\n",
    "    StandardScaler(with_mean=True), \n",
    "    LGBMRegressor()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression Results\n",
      "Train score: 0.7856521721316624\n",
      "Val score: 0.6598667763039183\n",
      "Test score: -634191920174675.2\n",
      "Val RMSE: 11592.25483002242\n",
      "Test RMSE: 307775792454.8226\n"
     ]
    }
   ],
   "source": [
    "lr_pipe.fit(X_train, y_train)\n",
    "train_score = lr_pipe.score(X_train, y_train)\n",
    "val_score = lr_pipe.score(X_val, y_val)\n",
    "test_score = lr_pipe.score(X_test, y_test)\n",
    "val_pred = lr_pipe.predict(X_val)\n",
    "test_pred = lr_pipe.predict(X_test)\n",
    "\n",
    "print('Linear Regression Results')\n",
    "print(\"Train score:\", train_score)\n",
    "print(\"Val score:\", val_score)\n",
    "print(\"Test score:\", test_score)\n",
    "print(\"Val RMSE:\", np.sqrt(mean_squared_error(y_val, val_pred)))\n",
    "print(\"Test RMSE:\", np.sqrt(mean_squared_error(y_test, test_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge Regression Results\n",
      "Train score: 0.788540105178146\n",
      "Val score: 0.6617008722247153\n",
      "Test score: 0.16998655757034553\n",
      "Val RMSE: 11560.958201057443\n",
      "Test RMSE: 11134.39614724146\n"
     ]
    }
   ],
   "source": [
    "ridge_pipe.fit(X_train, y_train)\n",
    "train_score = ridge_pipe.score(X_train, y_train)\n",
    "val_score = ridge_pipe.score(X_val, y_val)\n",
    "test_score = ridge_pipe.score(X_test, y_test)\n",
    "val_pred = ridge_pipe.predict(X_val)\n",
    "test_pred = ridge_pipe.predict(X_test)\n",
    "\n",
    "print('Ridge Regression Results')\n",
    "print(\"Train score:\", train_score)\n",
    "print(\"Val score:\", val_score)\n",
    "print(\"Test score:\", test_score)\n",
    "print(\"Val RMSE:\", np.sqrt(mean_squared_error(y_val, val_pred)))\n",
    "print(\"Test RMSE:\", np.sqrt(mean_squared_error(y_test, test_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso Regression Results\n",
      "Train score: 0.7885630987615739\n",
      "Val score: 0.6608535504829102\n",
      "Test score: 0.16747665879392504\n",
      "Val RMSE: 11575.427237931748\n",
      "Test RMSE: 11151.218231625555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\dsml\\rolex-price-predictor\\venv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.802e+08, tolerance: 2.578e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "lasso_pipe.fit(X_train, y_train)\n",
    "train_score = lasso_pipe.score(X_train, y_train)\n",
    "val_score = lasso_pipe.score(X_val, y_val)\n",
    "test_score = lasso_pipe.score(X_test, y_test)\n",
    "val_pred = lasso_pipe.predict(X_val)\n",
    "test_pred = lasso_pipe.predict(X_test)\n",
    "\n",
    "print('Lasso Regression Results')\n",
    "print(\"Train score:\", train_score)\n",
    "print(\"Val score:\", val_score)\n",
    "print(\"Test score:\", test_score)\n",
    "print(\"Val RMSE:\", np.sqrt(mean_squared_error(y_val, val_pred)))\n",
    "print(\"Test RMSE:\", np.sqrt(mean_squared_error(y_test, test_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForestRegressor Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestRegressor Results\n",
      "Train score: 0.9111163470883256\n",
      "Val score: 0.6872165810202439\n",
      "Test score: 0.3462975081804902\n",
      "Val RMSE: 11116.427840571896\n",
      "Test RMSE: 9881.30207602016\n"
     ]
    }
   ],
   "source": [
    "rf_pipe.fit(X_train, y_train)\n",
    "train_score = rf_pipe.score(X_train, y_train)\n",
    "val_score = rf_pipe.score(X_val, y_val)\n",
    "test_score = rf_pipe.score(X_test, y_test)\n",
    "val_pred = rf_pipe.predict(X_val)\n",
    "test_pred = rf_pipe.predict(X_test)\n",
    "\n",
    "print('RandomForestRegressor Results')\n",
    "print(\"Train score:\", train_score)\n",
    "print(\"Val score:\", val_score)\n",
    "print(\"Test score:\", test_score)\n",
    "print(\"Val RMSE:\", np.sqrt(mean_squared_error(y_val, val_pred)))\n",
    "print(\"Test RMSE:\", np.sqrt(mean_squared_error(y_test, test_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LightGBM Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM Results\n",
      "Train score: 0.6920469886102649\n",
      "Val score: 0.6921114456768066\n",
      "Test score: 0.36444207848654075\n",
      "Val RMSE: 11029.102278217319\n",
      "Test RMSE: 9743.201266241455\n"
     ]
    }
   ],
   "source": [
    "lgbm_pipe.fit(X_train, y_train)\n",
    "train_score = lgbm_pipe.score(X_train, y_train)\n",
    "val_score = lgbm_pipe.score(X_val, y_val)\n",
    "test_score = lgbm_pipe.score(X_test, y_test)\n",
    "val_pred = lgbm_pipe.predict(X_val)\n",
    "test_pred = lgbm_pipe.predict(X_test)\n",
    "\n",
    "print('LightGBM Results')\n",
    "print(\"Train score:\", train_score)\n",
    "print(\"Val score:\", val_score)\n",
    "print(\"Test score:\", test_score)\n",
    "print(\"Val RMSE:\", np.sqrt(mean_squared_error(y_val, val_pred)))\n",
    "print(\"Test RMSE:\", np.sqrt(mean_squared_error(y_test, test_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RFRegressor Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3300 candidates, totalling 16500 fits\n",
      "Best params: {'randomforestregressor__ccp_alpha': 0.03, 'randomforestregressor__max_depth': 9, 'randomforestregressor__max_features': 'sqrt', 'randomforestregressor__n_estimators': 50}\n",
      "Process took: 0:02:22.705324\n"
     ]
    }
   ],
   "source": [
    "# Start Time\n",
    "start = datetime.now()\n",
    "\n",
    "param_grid = {\n",
    "    'randomforestregressor__n_estimators': np.arange(10, 200, 20),\n",
    "    'randomforestregressor__max_depth' : np.arange(1, 11, 1),\n",
    "    'randomforestregressor__max_features': ['sqrt', 'log2', None],\n",
    "    'randomforestregressor__ccp_alpha': np.linspace(0, 0.05, 11)\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(rf_pipe, param_grid=param_grid, n_jobs=-1, verbose = 3)\n",
    "grid_search.fit(X_train, y_train)  \n",
    "print(\"Best params:\", grid_search.best_params_)\n",
    "\n",
    "# End Time\n",
    "end = datetime.now()\n",
    "print(\"Process took:\", end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Pickle RF model\n",
    "rf_pipe = make_pipeline(\n",
    "    StandardScaler(with_mean=True), \n",
    "    RandomForestRegressor(ccp_alpha = 0.03,\n",
    "                          max_depth = 9, \n",
    "                          max_features = 'sqrt', \n",
    "                          n_estimators = 50,\n",
    "                          random_state = 42,\n",
    "                          n_jobs=-1)\n",
    ")\n",
    "\n",
    "# filename= 'rfmodel.pkl'\n",
    "# pkl.dump(rf_pipe, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestRegressor Results\n",
      "Train score: 0.8606896974321481\n",
      "Val score: 0.7689864926942107\n",
      "Test score: 0.4640418843780375\n",
      "Val RMSE: 9553.4905603125\n",
      "Test RMSE: 8947.249160434125\n"
     ]
    }
   ],
   "source": [
    "rf_pipe.fit(X_train, y_train)\n",
    "train_score = rf_pipe.score(X_train, y_train)\n",
    "val_score = rf_pipe.score(X_val, y_val)\n",
    "test_score = rf_pipe.score(X_test, y_test)\n",
    "val_pred = rf_pipe.predict(X_val)\n",
    "test_pred = rf_pipe.predict(X_test)\n",
    "\n",
    "print('RandomForestRegressor Results')\n",
    "print(\"Train score:\", train_score)\n",
    "print(\"Val score:\", val_score)\n",
    "print(\"Test score:\", test_score)\n",
    "print(\"Val RMSE:\", np.sqrt(mean_squared_error(y_val, val_pred)))\n",
    "print(\"Test RMSE:\", np.sqrt(mean_squared_error(y_test, test_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LGBMRegressor Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4840 candidates, totalling 24200 fits\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7000000000000001\n",
      "Best params: {'lgbmregressor__boosting_type': 'dart', 'lgbmregressor__feature_fraction': 0.7000000000000001, 'lgbmregressor__learning_rate': 0.1, 'lgbmregressor__max_depth': 7}\n",
      "Process took: 0:00:31.706622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\dsml\\rolex-price-predictor\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "9200 fits failed out of a total of 24200.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "2200 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\admin\\dsml\\rolex-price-predictor\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\admin\\dsml\\rolex-price-predictor\\venv\\lib\\site-packages\\sklearn\\pipeline.py\", line 406, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\Users\\admin\\dsml\\rolex-price-predictor\\venv\\lib\\site-packages\\lightgbm\\sklearn.py\", line 895, in fit\n",
      "    super().fit(X, y, sample_weight=sample_weight, init_score=init_score,\n",
      "  File \"C:\\Users\\admin\\dsml\\rolex-price-predictor\\venv\\lib\\site-packages\\lightgbm\\sklearn.py\", line 748, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\admin\\dsml\\rolex-price-predictor\\venv\\lib\\site-packages\\lightgbm\\engine.py\", line 271, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"C:\\Users\\admin\\dsml\\rolex-price-predictor\\venv\\lib\\site-packages\\lightgbm\\basic.py\", line 2605, in __init__\n",
      "    train_set.construct()\n",
      "  File \"C:\\Users\\admin\\dsml\\rolex-price-predictor\\venv\\lib\\site-packages\\lightgbm\\basic.py\", line 1815, in construct\n",
      "    self._lazy_init(self.data, label=self.label,\n",
      "  File \"C:\\Users\\admin\\dsml\\rolex-price-predictor\\venv\\lib\\site-packages\\lightgbm\\basic.py\", line 1538, in _lazy_init\n",
      "    self.__init_from_np2d(data, params_str, ref_dataset)\n",
      "  File \"C:\\Users\\admin\\dsml\\rolex-price-predictor\\venv\\lib\\site-packages\\lightgbm\\basic.py\", line 1659, in __init_from_np2d\n",
      "    _safe_call(_LIB.LGBM_DatasetCreateFromMat(\n",
      "  File \"C:\\Users\\admin\\dsml\\rolex-price-predictor\\venv\\lib\\site-packages\\lightgbm\\basic.py\", line 125, in _safe_call\n",
      "    raise LightGBMError(_LIB.LGBM_GetLastError().decode('utf-8'))\n",
      "lightgbm.basic.LightGBMError: Check failed: (learning_rate) > (0.0) at D:\\a\\1\\s\\python-package\\compile\\src\\io\\config_auto.cpp, line 331 .\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2000 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\admin\\dsml\\rolex-price-predictor\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\admin\\dsml\\rolex-price-predictor\\venv\\lib\\site-packages\\sklearn\\pipeline.py\", line 406, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\Users\\admin\\dsml\\rolex-price-predictor\\venv\\lib\\site-packages\\lightgbm\\sklearn.py\", line 895, in fit\n",
      "    super().fit(X, y, sample_weight=sample_weight, init_score=init_score,\n",
      "  File \"C:\\Users\\admin\\dsml\\rolex-price-predictor\\venv\\lib\\site-packages\\lightgbm\\sklearn.py\", line 748, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\admin\\dsml\\rolex-price-predictor\\venv\\lib\\site-packages\\lightgbm\\engine.py\", line 271, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"C:\\Users\\admin\\dsml\\rolex-price-predictor\\venv\\lib\\site-packages\\lightgbm\\basic.py\", line 2605, in __init__\n",
      "    train_set.construct()\n",
      "  File \"C:\\Users\\admin\\dsml\\rolex-price-predictor\\venv\\lib\\site-packages\\lightgbm\\basic.py\", line 1815, in construct\n",
      "    self._lazy_init(self.data, label=self.label,\n",
      "  File \"C:\\Users\\admin\\dsml\\rolex-price-predictor\\venv\\lib\\site-packages\\lightgbm\\basic.py\", line 1538, in _lazy_init\n",
      "    self.__init_from_np2d(data, params_str, ref_dataset)\n",
      "  File \"C:\\Users\\admin\\dsml\\rolex-price-predictor\\venv\\lib\\site-packages\\lightgbm\\basic.py\", line 1659, in __init_from_np2d\n",
      "    _safe_call(_LIB.LGBM_DatasetCreateFromMat(\n",
      "  File \"C:\\Users\\admin\\dsml\\rolex-price-predictor\\venv\\lib\\site-packages\\lightgbm\\basic.py\", line 125, in _safe_call\n",
      "    raise LightGBMError(_LIB.LGBM_GetLastError().decode('utf-8'))\n",
      "lightgbm.basic.LightGBMError: Check failed: (feature_fraction) > (0.0) at D:\\a\\1\\s\\python-package\\compile\\src\\io\\config_auto.cpp, line 372 .\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5000 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\admin\\dsml\\rolex-price-predictor\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\admin\\dsml\\rolex-price-predictor\\venv\\lib\\site-packages\\sklearn\\pipeline.py\", line 406, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\Users\\admin\\dsml\\rolex-price-predictor\\venv\\lib\\site-packages\\lightgbm\\sklearn.py\", line 895, in fit\n",
      "    super().fit(X, y, sample_weight=sample_weight, init_score=init_score,\n",
      "  File \"C:\\Users\\admin\\dsml\\rolex-price-predictor\\venv\\lib\\site-packages\\lightgbm\\sklearn.py\", line 748, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\admin\\dsml\\rolex-price-predictor\\venv\\lib\\site-packages\\lightgbm\\engine.py\", line 271, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"C:\\Users\\admin\\dsml\\rolex-price-predictor\\venv\\lib\\site-packages\\lightgbm\\basic.py\", line 2610, in __init__\n",
      "    _safe_call(_LIB.LGBM_BoosterCreate(\n",
      "  File \"C:\\Users\\admin\\dsml\\rolex-price-predictor\\venv\\lib\\site-packages\\lightgbm\\basic.py\", line 125, in _safe_call\n",
      "    raise LightGBMError(_LIB.LGBM_GetLastError().decode('utf-8'))\n",
      "lightgbm.basic.LightGBMError: Check failed: config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f at D:\\a\\1\\s\\python-package\\compile\\src\\boosting\\rf.hpp, line 35 .\n",
      "\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\admin\\dsml\\rolex-price-predictor\\venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:953: UserWarning: One or more of the test scores are non-finite: [nan nan nan ... nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Start Time\n",
    "start = datetime.now()\n",
    "\n",
    "param_grid = {\n",
    "    'lgbmregressor__boosting_type' : ['gbdt', 'dart', 'goss', 'rf'],\n",
    "    'lgbmregressor__max_depth' : np.arange(1, 11, 1),\n",
    "#     'lgbmregressor__alpha' : np.logspace(-5, 5, 10),\n",
    "#     'lgbmregressor__lambda' : np.logspace(-5, 5, 10),\n",
    "    'lgbmregressor__learning_rate' : np.linspace(0, 1, 11),\n",
    "    'lgbmregressor__feature_fraction' : np.linspace(0, 1, 11)\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(lgbm_pipe, param_grid=param_grid, n_jobs=-1, verbose = 3)\n",
    "grid_search.fit(X_train, y_train)  \n",
    "print(\"Best params:\", grid_search.best_params_)\n",
    "\n",
    "# End Time\n",
    "end = datetime.now()\n",
    "print(\"Process took:\", end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.7000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7000000000000001\n"
     ]
    }
   ],
   "source": [
    "## Pickle RF model\n",
    "lgbm_pipe = make_pipeline(\n",
    "    StandardScaler(with_mean=True), \n",
    "    LGBMRegressor(boosting_type = 'dart', \n",
    "                  feature_fraction = 0.7000000000000001, \n",
    "                  learning_rate = 0.1, \n",
    "                  max_depth = 7)\n",
    ")\n",
    "\n",
    "lgbm_pipe.fit(Xtrain, ytrain)\n",
    "filename= 'lgbmmodel.pkl'\n",
    "pkl.dump(lgbm_pipe, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBMRegressor Results\n",
      "Train score: 0.5570079510870094\n",
      "Val score: 0.7057456038643679\n",
      "Test score: 0.6030743617587124\n",
      "Val RMSE: 10782.137648907155\n",
      "Test RMSE: 7699.786474338987\n"
     ]
    }
   ],
   "source": [
    "lgbm_pipe.fit(X_train, y_train)\n",
    "train_score = lgbm_pipe.score(X_train, y_train)\n",
    "val_score = lgbm_pipe.score(X_val, y_val)\n",
    "test_score = lgbm_pipe.score(X_test, y_test)\n",
    "val_pred = lgbm_pipe.predict(X_val)\n",
    "test_pred = lgbm_pipe.predict(X_test)\n",
    "\n",
    "print('LGBMRegressor Results')\n",
    "print(\"Train score:\", train_score)\n",
    "print(\"Val score:\", val_score)\n",
    "print(\"Test score:\", test_score)\n",
    "print(\"Val RMSE:\", np.sqrt(mean_squared_error(y_val, val_pred)))\n",
    "print(\"Test RMSE:\", np.sqrt(mean_squared_error(y_test, test_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Future work to combine multiple models into one pipeline for hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create models for each used in the Pipeline step\n",
    "rgr1 = LinearRegression()\n",
    "rgr2 = Ridge()\n",
    "rgr3 = Lasso()\n",
    "rgr4 = RandomForestRegressor(random_state = 42, n_jobs=-1)\n",
    "rgr5 = LGBMRegressor(random_state = 42, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline to be used for Hyperparameter tuning\n",
    "pipe = Pipeline([('scaler', StandardScaler(), ('regressor', rgr1))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "np.linspace(0, 0.05, 11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create parameter dictionaries\n",
    "\n",
    "\n",
    "## Linear Regression\n",
    "params1 = {}\n",
    "params1['regressor'] = [rgr1]\n",
    "\n",
    "\n",
    "## Ridge\n",
    "params2 = {}\n",
    "params2['regressor__alpha'] = np.logspace(-5, 5, 10)\n",
    "params2['regressor'] = [rgr2]\n",
    "\n",
    "\n",
    "## Lasso\n",
    "params3 = {}\n",
    "params3['regressor__alpha'] = np.logspace(-5, 5, 10)\n",
    "params3['regressor'] = [rgr3]\n",
    "\n",
    "\n",
    "## RandomForestRegressor\n",
    "params4 = {}\n",
    "params4['regressor__n_estimators'] = np.linspace(10, 200, 20)\n",
    "params4['regressor__max_depth'] = np.linspace(0, 10, 11)\n",
    "params4['regressor__max_features'] = ['sqrt', 'log2', None]\n",
    "params4['regressor__ccp_alpha'] = np.linspace(0, 0.05, 11)\n",
    "params4['regressor'] = [rgr4]\n",
    "\n",
    "\n",
    "## LGBMRegressor\n",
    "params5 = {}\n",
    "params5['regressor__boosting_type'] = ['gbdt', 'dart', 'goss', 'rf']\n",
    "params5['regressor__max_depth'] = np.linspace(0, 10, 11)\n",
    "params5['regressor__alpha'] = np.logspace(-5, 5, 10)\n",
    "params5['regressor__lambda'] = np.logspace(-5, 5, 10)\n",
    "params5['regressor__learning_rate'] = np.linspace(0, 1, 11)\n",
    "params5['regressor__feature_fraction'] = np.linspace(0, 1, 11)\n",
    "params5['regressor'] = [rgr5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List of parameter dictionaries\n",
    "# params = [params1]\n",
    "params = [params1, params2, params3, params4, params5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing GridSearchCV\n",
    "\n",
    "# Start Time\n",
    "start = datetime.now()\n",
    "\n",
    "# grid = RandomizedSearchCV(pipe, params, verbose=3, scoring='neg_mean_squared_error')\n",
    "# grid.fit(X_train, y_train)\n",
    "# grid.best_params_\n",
    "\n",
    "grid = GridSearchCV(pipe, params, verbose=3, scoring='neg_mean_squared_error')\n",
    "grid.fit(X_train, y_train)\n",
    "grid.best_params_\n",
    "\n",
    "# End Time\n",
    "end = datetime.now()\n",
    "print(\"Process took:\", end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "9e47a574da5ad346479a645ae2c39fe10a784865b81b7c753e106583b219afff"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
