{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build model for watch price utilizing linear regression and lightgbm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from lightgbm import LGBMRegressor\n",
    "import lightgbm as lgb\n",
    "import pickle\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "import statsmodels.api as sm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.linear_model import Lasso, Ridge, LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from datetime import date\n",
    "from tqdm import tqdm\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'data/dataWithCurrencyVer002.csv'\n",
    "file2 = 'data/reformatedAndOneHotEncodedDataVer011.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(file, index_col=0)\n",
    "## Re-ordering to ascending order\n",
    "df = df.iloc[::-1]\n",
    "df['listing__statPrice'] = df['listing__statPrice'].round(2)\n",
    "df.drop(df[df['Age'] == '41mm'].index, inplace=True)\n",
    "df.drop(df[df['Age'] == '2918'].index, inplace=True)\n",
    "df['Age'] = df['Age'].str[:4].astype('int')\n",
    "df['Age'] = date.today().year - df['Age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.replace(np.nan, 'Missing', inplace=True)\n",
    "df['Age'] = date.today().year - df['Age'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['listing__statPrice']\n",
    "X = df.drop(columns=['product-subtitle', 'Model', 'LOT'], axis=1)\n",
    "# X = data.drop(['gross'], axis=1)\n",
    "\n",
    "# Shuffle to false to handle time data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle=False, test_size = 0.2)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, shuffle=False, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = ['language', 'country', 'rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical Preprocessor\n",
    "categorical_preprocessor = Pipeline(\n",
    "    steps=[\n",
    "        # Change to 'ignore' if error raised\n",
    "        (\"OHE\", OneHotEncoder(handle_unknown='error', drop='first'))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combine preprocessors\n",
    "#Commenting out TfidfVectorizer as it does not help the model\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('text', text_preprocesser, 'plot'),\n",
    "        ('category', categorical_preprocessor, categorical_cols)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change file path to data\n",
    "fileName = 'data/reformatedAndOneHotEncodedDataVer011.csv'\n",
    "df = pd.read_csv(fileName)\n",
    "# df = df.iloc[::-1]\n",
    "\n",
    "def split_data(X, y, frac: float = 0.2) -> tuple:\n",
    "    \"\"\"Splits data so that it returns a train / test split with a given fraction\"\"\"\n",
    "\n",
    "    # cutoff point for training / test split\n",
    "    idx_cutoff = int(X.shape[0] * (1 - frac))\n",
    "\n",
    "    X_train, X_test, y_train, y_test = X.iloc[:idx_cutoff], X.iloc[idx_cutoff:], y.iloc[:idx_cutoff], y.iloc[idx_cutoff:]\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reindex(index=df.index[::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_list_train = list(df.columns)\n",
    "col_list_train.remove('listing__statPrice')\n",
    "# col_list_train.remove('id')\n",
    "\n",
    "\n",
    "dfX_train = df[col_list_train]\n",
    "dfy_train = df['listing__statPrice']\n",
    "\n",
    "X_train, X_test, y_train, y_test = split_data(dfX_train, dfy_train, 0.2)\n",
    "\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_list_train = list(df.columns)\n",
    "col_list_train.remove('listing__statPrice')\n",
    "# col_list_train.remove('id')\n",
    "\n",
    "\n",
    "dfX_train = df[col_list_train]\n",
    "dfy_train = df['listing__statPrice']\n",
    "\n",
    "X_train, X_test, y_train, y_test = split_data(dfX_train, dfy_train, 0.2)\n",
    "\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stdScale = StandardScaler()\n",
    "stdScale.fit_transform(X_train)\n",
    "stdScale.transform(X_test)\n",
    "\n",
    "#Set the minimum error arbitrarily large\n",
    "min = 99999999999999999999999 \n",
    "count = 0 #Used for keeping track of the iteration number\n",
    "#How many runs to perform using randomly selected hyperparameters\n",
    "iterations = 1000\n",
    "for i in range(iterations):\n",
    "    print('iteration number', count)\n",
    "    count += 1 #increment count\n",
    "\n",
    "    param = {} #initialize parameters\n",
    "    param['learning_rate'] = np.random.uniform(0, 1)\n",
    "    # param['num_iterations'] = np.random.randint(100,1000)\n",
    "    param['boosting_type'] = np.random.choice(['gbdt'])\n",
    "    # param['objective'] = 'binary'\n",
    "    param['metric'] = 'mse'\n",
    "    param['feature_fraction'] = np.random.uniform(0, 1)\n",
    "    param['num_leaves'] = np.random.randint(5, 300)\n",
    "    param['min_data_in_leaf'] = np.random.randint(5, 200)\n",
    "    param['max_depth'] = np.random.randint(5, 300)\n",
    "    param['early_stopping_round'] = 5\n",
    "    iterations = np.random.randint(10, 10000)\n",
    "    print(param, iterations)#Train using selected parameters\n",
    "    lgbm = LGBMRegressor(**param)\n",
    "    lgbm.fit(X_train,y_train, eval_set = [(X_test, y_test) , (X_train, y_train)], eval_metric = 'rmse')\n",
    "    prediction = lgbm.predict(X_test)\n",
    "    logloss = mean_squared_error(y_true = y_test, y_pred = prediction, squared = False)\n",
    "\n",
    "    print('logloss:', logloss)\n",
    "    if logloss < min:\n",
    "        min = logloss\n",
    "        pp = param\n",
    "\n",
    "print(\"*\" * 100)\n",
    "print('Minimum is: ', min)\n",
    "print('Used params', pp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stdScale = StandardScaler()\n",
    "stdScale.fit_transform(X_train)\n",
    "stdScale.transform(X_test)\n",
    "\n",
    "lgbm_train = LGBMRegressor(learning_rate = 0.12672753417697025, boosting_type = 'gbdt', metric = 'rmse', feature_fraction = 0.25975871059387023, num_leaves = 261, min_data_in_leaf = 11, max_depth = 137, early_stopping_round = 5)\n",
    "lgbm_train.fit(X_train,y_train, eval_set = [(X_test, y_test) , (X_train, y_train)], eval_metric = 'rmse')\n",
    "prediction = lgbm_train.predict(X_test)\n",
    "print(mean_squared_error(y_true = y_test, y_pred = prediction, squared = False))\n",
    "# lgb.plot_importance(lgbm)\n",
    "# print('Training accuracy {:.4f}'.format(lgbm.score(X_train,y_train)))\n",
    "# print('Testing accuracy {:.4f}'.format(lgbm.score(X_test,y_test)))\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model for linear regression\n",
    "mod_pipeline = Pipeline([('scaler', StandardScaler()), ('linearRegression', LinearRegression())])\n",
    "mod_pipeline.fit(X_train, y_train)\n",
    "test_score = mod_pipeline.score(X_test, y_test)\n",
    "test_score\n",
    "## 0.543308485096857 with model training recent sales\n",
    "\n",
    "\n",
    "## -5.813872016504329e+21 data reversed using onehotencode data\n",
    "## 0.5415915991663093"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_pipe = make_pipeline(\n",
    "    preprocessor, \n",
    "    StandardScaler(with_mean=False), \n",
    "    LinearRegression()\n",
    ")\n",
    "\n",
    "lasso_pipe = make_pipeline(\n",
    "    preprocessor, \n",
    "    StandardScaler(with_mean=False), \n",
    "    Lasso()\n",
    ")\n",
    "\n",
    "ridge_pipe = make_pipeline(\n",
    "    preprocessor, \n",
    "    StandardScaler(with_mean=False), \n",
    "    Ridge()\n",
    ")\n",
    "\n",
    "rf_pipe = make_pipeline(\n",
    "    preprocessor, \n",
    "    StandardScaler(with_mean=False), \n",
    "    RandomForestRegressor(random_state = 42)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_pipe.fit(X_train, y_train)\n",
    "train_score = lr_pipe.score(X_train, y_train)\n",
    "val_score = lr_pipe.score(X_val, y_val)\n",
    "test_score = lr_pipe.score(X_test, y_test)\n",
    "val_pred = lr_pipe.predict(X_val)\n",
    "test_pred = lr_pipe.predict(X_test)\n",
    "\n",
    "print('Linear Regression Results')\n",
    "print(\"Train score:\", train_score)\n",
    "print(\"Val score:\", val_score)\n",
    "print(\"Test score:\", test_score)\n",
    "print(\"Val RMSE:\", np.sqrt(mean_squared_error(y_val, val_pred)))\n",
    "print(\"Test RMSE:\", np.sqrt(mean_squared_error(y_test, test_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'watches_lgbm_model.pkl'\n",
    "pickle.dump(lgbm, open(filename, 'wb'))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "9e47a574da5ad346479a645ae2c39fe10a784865b81b7c753e106583b219afff"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
